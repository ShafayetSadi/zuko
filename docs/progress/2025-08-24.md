# Zuko Devlog – Week 1

## Overview

This is the **beginning of Zuko**, my open-source **code execution engine**. The goal is to build a **secure, scalable, and accurate online judge backend** that can be used in running untrusted codes, contest environment codes and later power RUET Analytical Programming Lab (RAPL)’s contest platform (my hobby project).

I focused on building the **core execution engine** — the heart of Zuko.

---

## What I Accomplished

### 1. Project Setup

- Created the initial project structure:

  ```text
  zuko/
  ├── zuko/
  │   ├── api/              # FastAPI endpoints
  │   ├── core/             # Execution logic
  │   ├── models/           # Pydantic models
  │   └── workers/          # Future async workers
  ├── docker/               # Language-specific Dockerfiles
  ├── tests/                # Unit & stress tests
  └── main.py               # FastAPI entrypoint
  ```

- Decided on **FastAPI** as the backend framework.
- Planned to make Zuko a **standalone open-source engine**.

### 2. Code Execution Engine (MVP)

- Implemented the first version of `DockerExecutor`:
  - Runs user code inside a **Docker container**.
  - Supports **Python 3.12** initially.
  - Enforces **CPU & memory limits** (`nano_cpus`, `mem_limit`, `pids_limit`).
  - Sandboxes execution (no network, read-only FS, no new privileges).

### 3. Accurate Time & Memory Measurement

- Initially tried to measure time and memory from **Docker stats API**
- But it has shown to be unreliable (returned `0, 0` for fast programs).
- Then switched to **`/usr/bin/time`** for **reliability and gives similar measurements to codeforces**:
  - **CPU time** = user + system time (ms).
  - **Memory** = peak RSS (KB).
- Built a **custom Python Docker image** (`zuko-python:3.12`) with `time` pre-installed.
- Now Zuko reports results like:

  ```json
  {
    "status": "OK",
    "stdout": "Hello Zuko!",
    "stderr": "",
    "exit_code": 0,
    "time_used": 10,
    "memory_used": 9200
  }
  ```

### 4. Stress Testing

- Added **baseline, CPU-heavy, memory-heavy, I/O, error, and timeout** test cases.

### 5. Documentation & Workflow

- Set up `docs/progress/` for weekly devlogs.
- Planned `CHANGELOG.md` for milestone tracking.
- Adopted **Conventional Commits** for clean git history.

---

## Challenges Faced

- **Docker stats unreliability**: Fast programs finished before stats were collected.
- **Missing `/usr/bin/time`** in slim images → solved by building a custom image.
- **Balancing accuracy vs. performance**: `/usr/bin/time` adds slight overhead, but accuracy is worth it.

---

## Next Week’s Goals

- Add **C++ support** (compile + run inside Docker).
- Add **multi-testcase execution** (loop over test cases, return AC/WA/TLE verdicts).
- Expand **test suite** with more competitive programming-style problems.
- Start drafting **API docs** for `/execute` and future endpoints.

---

## Reflections

This week was about **laying the foundation**. I now have:

- A working **sandboxed execution engine**.
- **Accurate time and memory measurement** like Codeforces.
- A clear roadmap for multi-language and contest features.

Zuko is no longer just an idea — it’s running real code, measuring it, and returning results.

---

## Closing Note

Week 1 was all about **getting the core right**. Next week, I’ll focus on **expanding language support and testcases** so Zuko feels more like a real online judge.

Stay tuned — Zuko is just getting started.
